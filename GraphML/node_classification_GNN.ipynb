{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec0e1faf",
   "metadata": {},
   "source": [
    "# Node Classification using Graph Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e6909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check CUDA Version\n",
    "!python -c \"import torch; print(torch.version.cuda)\"\n",
    "\n",
    "# Install Pytorch Geometric\n",
    "!pip install -q torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.6.0.html\n",
    "!pip install -q torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.6.0.html\n",
    "!pip install -q git+https://github.com/rusty1s/pytorch_geometric.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3017510b",
   "metadata": {},
   "source": [
    "## Knowledge Graphs and Node Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b919b6d",
   "metadata": {},
   "source": [
    "There are two special properties we are dealing with in this example:\n",
    "1. We have one large graph and not many individual graphs (like molecules)\n",
    "2. We infer on unlabeled nodes in this large graph and hence perform node-level predictions --> We have to use different nodes of the graph depending on what we want to do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a40f4ea",
   "metadata": {},
   "source": [
    "## Dataset Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41890301",
   "metadata": {},
   "source": [
    "There exists different datasets in PyTorch Geometric that can be used to perform Node Classification on large Knowledge Graphs e.g. Karate Network or Cora. We will use Cora to showcase the use of binary masks for node-level predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6c1eac",
   "metadata": {},
   "source": [
    "#### What is the Cora Dataset?\n",
    "The Cora dataset consists of 2708 scientific publications classified into one of seven classes. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary. The dictionary consists of 1433 unique words.\n",
    "\n",
    "- Nodes = Publications (Papers, Books ...)\n",
    "- Edges = Citations\n",
    "- Node Features = word vectors\n",
    "- 7 Labels = Pubilcation type e.g. Neural_Networks, Rule_Learning, Reinforcement_Learning, \tProbabilistic_Methods...\n",
    "\n",
    "We normalize the features using torch geometric's transform functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68c96361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6393cf4",
   "metadata": {},
   "source": [
    "PyTorch Geometric provides different functions to investigate the dataset (e.g. node degrees, self-loops ect.) - You can find more of them in the documentation or in [this notebook](https://colab.research.google.com/drive/14OvFnAXggxB8vM4e8vSURUp1TaKnovzX?usp=sharing#scrollTo=eqWR0j_kIx67)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab74438e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs: 1\n",
      "Number of features: 1433\n",
      "Number of classes: 7\n",
      "==================================================\n",
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
      "Number of nodes: 2708\n",
      "Number of edges: 10556\n",
      "Number of training nodes: 140\n",
      "Training node label rate: 0.05\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "# Get some basic info about the dataset\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "print(50*'=')\n",
    "\n",
    "# There is only one graph in the dataset, use it as new data object\n",
    "data = dataset[0]  \n",
    "\n",
    "# Gather some statistics about the graph.\n",
    "print(data)\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60132d5",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- We only have a relatively small set of training nodes (20 nodes per class)\n",
    "- There are binary test, train and validation masks of the size #nodes (they tell us which node can be used for which task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fedfa61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 1433])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.1111, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.x.shape) # [No. Nodes x Features]\n",
    "\n",
    "# Print some of the normalized word counts of the first datapoint\n",
    "data.x[0][:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268c93e5",
   "metadata": {},
   "source": [
    "Why do we even use the graph structure - aren't the features enough?\n",
    "\n",
    "- Apparently, simple MLP models perform a lot worse than GNNs on this type of task, as the citation information is crucial for a correct classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3faaf66",
   "metadata": {},
   "source": [
    "How do the labels look like?\n",
    "- They are encoded as numeric value between 0-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a92bc88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 4,  ..., 3, 3, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e11dd374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  ...,  True,  True,  True])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data.test_mask) == data.num_nodes)\n",
    "data.test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "975062a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,  633],\n",
       "        [   0, 1862],\n",
       "        [   0, 2582],\n",
       "        ...,\n",
       "        [2707,  598],\n",
       "        [2707, 1473],\n",
       "        [2707, 2706]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index.t()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e696ac",
   "metadata": {},
   "source": [
    "## Graph Neural Network for Node Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42317823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(1433, 16)\n",
      "  (conv2): GCNConv(16, 16)\n",
      "  (out): Linear(in_features=16, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv #GATConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "        # Initialize the layers\n",
    "        self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.out = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # First Message Passing Layer (Transformation)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        # Second Message Passing Layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        # Output layer \n",
    "        x = F.softmax(self.out(x), dim=1)\n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=16)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4722d06e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
